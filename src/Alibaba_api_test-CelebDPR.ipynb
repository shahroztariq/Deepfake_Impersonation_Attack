{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Conda Env Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.executable.split('/')[-3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_filename='alibaba_CelebDPR.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.face import FaceClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from array import array\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from PIL import Image\n",
    "import csv\n",
    "from time import sleep\n",
    "from glob import glob\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print (sys.path)\n",
    "print(os. getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding=utf-8\n",
    "# The ImageSyncScanRequest operation returns image moderation results in real time.\n",
    "\n",
    "from aliyunsdkcore import client\n",
    "from aliyunsdkgreen.request.v20180509 import ImageSyncScanRequest\n",
    "from aliyunsdkgreen.request.extension import ClientUploader\n",
    "from aliyunsdkgreenextension.request.extension import HttpContentHelper\n",
    "import json\n",
    "import uuid\n",
    "import sys\n",
    "\n",
    "# Set the default encoding to UTF-8 to support a local path containing Chinese characters.\n",
    "# Add the following code snippet if you use Python 2. If you use Python 3, remove it.\n",
    "if sys.version_info[0] == 2:\n",
    "    reload(sys)\n",
    "    sys.setdefaultencoding('utf-8')\n",
    "\n",
    "# Use the AccessKey ID and AccessKey secret of your Alibaba Cloud account.\n",
    "clt = client.AcsClient(\"\", \"\", \"\")\n",
    "request = ImageSyncScanRequest.ImageSyncScanRequest()\n",
    "request.set_accept_format('JSON')\n",
    "\n",
    "# Use the path of your local image.\n",
    "# Upload the local image to the server.\n",
    "uploader = ClientUploader.getImageClientUploader(clt)\n",
    "url = uploader.uploadFile('Similarity/CelebDPR/real/Scarlett Johansson.jpg')\n",
    "\n",
    "# Set the url parameter to the image URL submitted to the server.\n",
    "task = {\"dataId\": str(uuid.uuid1()),\n",
    "         \"url\":url\n",
    "        }\n",
    "\n",
    "# Create one task for each image to be moderated.\n",
    "# If you moderate multiple images in a request, the total response time that the server spends processing the request starts from when the request is initiated to when the last image is moderated.\n",
    "# Generally, the average response time of moderating multiple images in a request is longer than that of moderating a single image. The more images you submit at a time, the higher the probability that the average response time will be extended.\n",
    "# The sample code uses a single image as an example. If you want to moderate multiple images at a time, create one task for each image to be moderated.\n",
    "# The system charges you based on the moderation scenario that you specify.\n",
    "# You can send a request to moderate multiple images at a time and specify multiple moderation scenarios for each image. The expenses of all scenarios are calculated separately and summed up.\n",
    "# For example, if you moderate two images for both pornography and terrorist content, you are charged for moderating two images for pornography and two images for terrorist content.\n",
    "request.set_content(HttpContentHelper.toValue({\"tasks\": [task], \"scenes\": [\"porn\"]}))\n",
    "response = clt.do_action_with_exception(request)\n",
    "print(response)\n",
    "result = json.loads(response)\n",
    "if 200 == result[\"code\"]:\n",
    "    taskResults = result[\"data\"]\n",
    "    for taskResult in taskResults:\n",
    "        if (200 == taskResult[\"code\"]):\n",
    "            sceneResults = taskResult[\"results\"]\n",
    "            for sceneResult in sceneResults:\n",
    "                # Take a further action on the image based on the values of the scene and suggestion parameters.\n",
    "                # do something\n",
    "                scene = sceneResult[\"scene\"]\n",
    "                suggestion = sceneResult[\"suggestion\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Setting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_key = \"your key\"\n",
    "endpoint=\"your endpoint\"\n",
    "computervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(subscription_key))\n",
    "subscription_key = \"your key\"\n",
    "endpoint=\"your endpoint\"\n",
    "face_client=FaceClient(endpoint, CognitiveServicesCredentials(subscription_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CelebDPR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Describe an Image - local\n",
    "This example describes the contents of an image with the confidence score.'Scarlett Johansson_fake.png'\n",
    "'''\n",
    "def describe_image(filename):\n",
    "#     print(\"===== Describe an image - local =====\")\n",
    "    # Call API\n",
    "    image= open(filename,\"rb\")\n",
    "    description_results = computervision_client.describe_image_in_stream(image)\n",
    "\n",
    "    # Get the captions (descriptions) from the response, with confidence level\n",
    "#     print(\"Description of local image: \")\n",
    "    if (len(description_results.captions) == 0):\n",
    "#         print(\"No description detected.\")\n",
    "        return \"No description detected.\"\n",
    "    else:\n",
    "        for caption in description_results.captions:\n",
    "#             print(\"'{}' with confidence {:.2f}%\".format(caption.text, caption.confidence * 100))\n",
    "            return \"'{}' with confidence {:.2f}%\".format(caption.text, caption.confidence * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect Domain-specific Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Detect Domain-specific Content - local\n",
    "This example detects celebrites and landmarks in local images.\n",
    "'''\n",
    "def domain_specific_content(filename):\n",
    "#     print(\"===== Detect Domain-specific Content - local =====\")\n",
    "    # Image of one or more celebrities\n",
    "    image= open(filename,\"rb\")\n",
    "    # image = image.read('Scarlett.png')\n",
    "\n",
    "    # Call API with content type (celebrities) and URL\n",
    "    detect_domain_results_celebs_remote = computervision_client.analyze_image_by_domain_in_stream(\"celebrities\", image)\n",
    "    # Print detection results with name\n",
    "#     print(\"Celebrities in the local image:\")\n",
    "    if len(detect_domain_results_celebs_remote.result[\"celebrities\"]) == 0:\n",
    "        print(\"No celebrities detected.\")\n",
    "        return \"\",\"\"\n",
    "    else:\n",
    "        for celeb in detect_domain_results_celebs_remote.result[\"celebrities\"]:\n",
    "#             print(celeb[\"name\"])\n",
    "#             print(celeb[\"confidence\"])\n",
    "            return celeb[\"name\"],celeb[\"confidence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(filename):\n",
    "    return os.path.splitext(os.path.basename(filename))[0].split(\"_\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_similarity(src_image, tar_image):\n",
    "    # Detect a face in an image that contains a single face\n",
    "    src_image_name = os.path.basename(src_image)\n",
    "    detected_faces = face_client.face.detect_with_stream(open(src_image,\"rb\"))\n",
    "    if not detected_faces:\n",
    "        print('No face detected from image {}'.format(single_image_name))\n",
    "        return 0\n",
    "#         raise Exception('No face detected from image {}'.format(single_image_name))\n",
    "\n",
    "    # Display the detected face ID in the first single-face image.\n",
    "    # Face IDs are used for comparison to faces (their IDs) detected in other images.\n",
    "#     print('Detected face ID from', single_image_name, ':')\n",
    "#     for face in detected_faces: \n",
    "#         print (face.face_id)\n",
    "#     print()\n",
    "\n",
    "    # Save this ID for use in Find Similar\n",
    "    first_image_face_ID = detected_faces[0].face_id\n",
    "    \n",
    "    multi_image_name = os.path.basename(tar_image)\n",
    "    detected_faces2 = face_client.face.detect_with_stream(open(tar_image,\"rb\"))\n",
    "    if not detected_faces2:\n",
    "        print('No face detected from image {}'.format(multi_image_name))\n",
    "        return 0\n",
    "#         raise Exception('No face detected from image {}'.format(multi_image_name))\n",
    "    \n",
    "    # Search through faces detected in group image for the single face from first image.\n",
    "    # First, create a list of the face IDs found in the second image.\n",
    "    second_image_face_IDs = list(map(lambda x: x.face_id, detected_faces2))\n",
    "    # Next, find similar face IDs like the one detected in the first image.\n",
    "    similar_faces = face_client.face.find_similar(face_id=first_image_face_ID, face_ids=second_image_face_IDs)\n",
    "    \n",
    "    if not similar_faces:\n",
    "        print('No similar faces found in', multi_image_name, '.')\n",
    "        return 0\n",
    "    else:\n",
    "        # Print the details of the similar faces detected\n",
    "#         print('Similar faces found in', multi_image_name + ':')\n",
    "        for face in similar_faces:\n",
    "        #     print(face)\n",
    "            return face.confidence\n",
    "#             print('  Confidence:', face.confidence)\n",
    "#             first_image_face_ID = face.face_id\n",
    "#             # The similar face IDs of the single face image and the group image do not need to match, \n",
    "#             # they are only used for identification purposes in each image.\n",
    "#             # The similar faces are matched using the Cognitive Services algorithm in find_similar().\n",
    "#             face_info = next(x for x in detected_faces2 if x.face_id == first_image_face_ID)\n",
    "#             if face_info:\n",
    "#                 print('  Face ID: ', first_image_face_ID)\n",
    "#                 print('  Face rectangle:')\n",
    "#                 print('    Left: ', str(face_info.face_rectangle.left))\n",
    "#                 print('    Top: ', str(face_info.face_rectangle.top))\n",
    "#                 print('    Width: ', str(face_info.face_rectangle.width))\n",
    "#                 print('    Height: ', str(face_info.face_rectangle.height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open(result_filename, 'w', newline='')\n",
    "writer = csv.writer(file)\n",
    "writer.writerow([\"Filename\", \"Src\",\"Tar\", \"Src Pred.\", \"Src Conf.\", \"Tar Pred.\",\"Tar Conf.\", \"Similarity\",\"Src Des\", \"Tar Des\"])\n",
    "file.close()\n",
    "actors_list=glob(\"/home/sha/project/adversarial_deepfake/src/Similarity/CelebDPR/fake/*\")\n",
    "count=0\n",
    "skip=0\n",
    "for actor in actors_list:\n",
    "    count+=1\n",
    "#     if skip ==0:\n",
    "#         if os.path.basename(actor) ==\"June Lapine Aka Shoe0nHead\":\n",
    "#             skip=1\n",
    "#         else:\n",
    "#             continue\n",
    "#     print(os.path.basename(actor))\n",
    "#     break\n",
    "    \n",
    "    real_image=os.path.join(\"/home/sha/project/adversarial_deepfake/src/Similarity/CelebDPR/real\",\n",
    "                                os.path.basename(actor)+\".jpg\")\n",
    "    fake_images_list=glob(os.path.join(actor,\"*\"))\n",
    "    print(real_image)\n",
    "#     pprint(fake_images_list)\n",
    "#     continue\n",
    "    result_real_pred,result_real_conf=domain_specific_content(real_image)\n",
    "    real_des=describe_image(real_image)\n",
    "    src=get_name(real_image)\n",
    "    for fake_image in fake_images_list:\n",
    "        print(fake_image)\n",
    "#         continue\n",
    "        result_fake_pred,result_fake_conf=domain_specific_content(fake_image)\n",
    "        fake_des=describe_image(fake_image)\n",
    "        tar=get_name(fake_image)\n",
    "        similarity=check_similarity(real_image,fake_image)\n",
    "#             print(fake_image,src,tar,\n",
    "#                   result_real_pred,result_real_conf,\n",
    "#                   result_fake_pred,result_fake_conf,\n",
    "#                   similarity,real_des,fake_des)\n",
    "        file=open(result_filename, 'a', newline='')\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([fake_image,src,tar,\n",
    "              result_real_pred,result_real_conf,\n",
    "              result_fake_pred,result_fake_conf,\n",
    "              similarity,real_des,fake_des])\n",
    "        file.close()\n",
    "#             sleep(10)\n",
    "#             break\n",
    "#         break\n",
    "#     break\n",
    "# file.close()\n",
    "print(\"Total:\",count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}